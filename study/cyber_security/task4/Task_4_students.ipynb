{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация тренировочного и тестового датасетов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем нужные библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import classification_report\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем предварительно обработанный датасет и удалим все строки, с пропусками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>date</th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>info@global-change.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>next wave energi trade</td>\n",
       "      <td>energi industri profession global chang associ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>info@pmaconference.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>regist next txu capac auction</td>\n",
       "      <td>regist next txu energi capac auction new regis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>info@pmaconference.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>merchant power monthli free sampl</td>\n",
       "      <td>merchant power monthli month s issu almost mw ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>bruno@firstconf.com</td>\n",
       "      <td>energynews@fc.ease.lsoft.com</td>\n",
       "      <td>eyeforenergi updat</td>\n",
       "      <td>welcom week s eyeforenergi updat refresh memor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>deanrogers@energyclasses.com</td>\n",
       "      <td>michelle.lokay@enron.com</td>\n",
       "      <td>deriv earli bird til march houston</td>\n",
       "      <td>deriv energi profession two full day april ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30687</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>jacob rzucidlo &lt;lavoneaker@stalag13.com&gt;</td>\n",
       "      <td>johnny wynott &lt;varou@iit.demokritos.gr&gt;</td>\n",
       "      <td>cpu pain m edicati n ship d r</td>\n",
       "      <td>arrghh west amnstv amlsmith basu petrom qureai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30688</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>hal leake &lt;annettgaskell@buglover.net&gt;</td>\n",
       "      <td>renato mooney &lt;sigletos@iit.demokritos.gr&gt;</td>\n",
       "      <td>dn troubl f r ee</td>\n",
       "      <td>dn troubl f r ee angiospasma zekauskasa anarti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30689</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>dr collins khumalo &lt;khumalo_20@sunumail.sn&gt;</td>\n",
       "      <td>khumalo_20@sunumail.sn</td>\n",
       "      <td>dr collin khumalo</td>\n",
       "      <td>dr collin khumalo attn mr presid dr collin khu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30690</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Customer Support &lt;support@citibank.com&gt;</td>\n",
       "      <td>Paliourg &lt;paliourg@iit.demokritos.gr&gt;</td>\n",
       "      <td>dear custom detail compromis</td>\n",
       "      <td>dear custom detail compromis dear custom recen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30691</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Tapanga Cribbin &lt;James_Lam@cnwl.igs.net&gt;</td>\n",
       "      <td>paliourg@iit.demokritos.gr</td>\n",
       "      <td>fwd great news</td>\n",
       "      <td>state shall without consent congress lay impos...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29890 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  date                                         from  \\\n",
       "0          0     4                       info@global-change.com   \n",
       "1          0     1                       info@pmaconference.com   \n",
       "2          0     6                       info@pmaconference.com   \n",
       "3          0     3                          bruno@firstconf.com   \n",
       "4          0     1                 deanrogers@energyclasses.com   \n",
       "...      ...   ...                                          ...   \n",
       "30687      1     3     jacob rzucidlo <lavoneaker@stalag13.com>   \n",
       "30688      1     5       hal leake <annettgaskell@buglover.net>   \n",
       "30689      1     2  dr collins khumalo <khumalo_20@sunumail.sn>   \n",
       "30690      1     6      Customer Support <support@citibank.com>   \n",
       "30691      1     6     Tapanga Cribbin <James_Lam@cnwl.igs.net>   \n",
       "\n",
       "                                               to  \\\n",
       "0                        michelle.lokay@enron.com   \n",
       "1                        michelle.lokay@enron.com   \n",
       "2                        michelle.lokay@enron.com   \n",
       "3                    energynews@fc.ease.lsoft.com   \n",
       "4                        michelle.lokay@enron.com   \n",
       "...                                           ...   \n",
       "30687     johnny wynott <varou@iit.demokritos.gr>   \n",
       "30688  renato mooney <sigletos@iit.demokritos.gr>   \n",
       "30689                      khumalo_20@sunumail.sn   \n",
       "30690       Paliourg <paliourg@iit.demokritos.gr>   \n",
       "30691                  paliourg@iit.demokritos.gr   \n",
       "\n",
       "                                  subject  \\\n",
       "0                  next wave energi trade   \n",
       "1           regist next txu capac auction   \n",
       "2       merchant power monthli free sampl   \n",
       "3                      eyeforenergi updat   \n",
       "4      deriv earli bird til march houston   \n",
       "...                                   ...   \n",
       "30687       cpu pain m edicati n ship d r   \n",
       "30688                    dn troubl f r ee   \n",
       "30689                   dr collin khumalo   \n",
       "30690        dear custom detail compromis   \n",
       "30691                      fwd great news   \n",
       "\n",
       "                                                    body  \n",
       "0      energi industri profession global chang associ...  \n",
       "1      regist next txu energi capac auction new regis...  \n",
       "2      merchant power monthli month s issu almost mw ...  \n",
       "3      welcom week s eyeforenergi updat refresh memor...  \n",
       "4      deriv energi profession two full day april ear...  \n",
       "...                                                  ...  \n",
       "30687  arrghh west amnstv amlsmith basu petrom qureai...  \n",
       "30688  dn troubl f r ee angiospasma zekauskasa anarti...  \n",
       "30689  dr collin khumalo attn mr presid dr collin khu...  \n",
       "30690  dear custom detail compromis dear custom recen...  \n",
       "30691  state shall without consent congress lay impos...  \n",
       "\n",
       "[29890 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(os.getcwd(), 'Task_4_prepprocessed.csv'))\n",
    "df = df.dropna()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним результаты, полученные при использовании трех различных способов векторизации:\n",
    "<ol>\n",
    "    <li>Базовый (в качестве предиктора используется только <code>body</code>).\n",
    "    <li>В качестве предикторов используем объединенные признаки <code>subject</code> и <code>body</code>, а также день недели, полученный из колонки <code>date</code>. \n",
    "    <li>Аналогично 1., только с использованием n-грамм.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для базового алгоритма из загруженного датасета возьмем только колонку <code>body</code> и колонку <code>class</code> с обозначением класса сообщения (идет первой)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df.iloc[:, 5], df.iloc[:,0], test_size=0.3, random_state=65)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы не модифицировать данные, использующиеся для базового алгоритма, сделаем глубокую копию данных для их дальнейшего преобразования. В частности, на копии произведем конкатенацию колонок `subject` и `body`. При разделении копии на тренировочный и тестовый наборы используем тот же `random_state`, что и для основого алгоритма, в целях сохранения соответствия полученных наборов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy(deep = True)\n",
    "\n",
    "for i in range(len(df_copy)):\n",
    "    if df.iat[i, 4] != '':\n",
    "        try:\n",
    "            df_copy.iat[i, 5] = df_copy.iat[i, 4] + ' ' + df_copy.iat[i, 5]\n",
    "        except:\n",
    "            print(\"Something got wrong!\")\n",
    "            \n",
    "x_train_b, x_test_b, _, _ = train_test_split(\n",
    "    df_copy.iloc[:, [1, 5]], df_copy.iloc[:,0], test_size=0.3, random_state=65)\n",
    "\n",
    "# y_train_b и y_test_b совпадают с y_train, y_test. Хранить их отдельно надобности нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Генерация признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для базового алгоритма сначала из тренировочного набора данных составим словарь, используемый для векторизации и генерации признаков TF-IDF, во время преобразования тренировочного набора данных. Затем этот же словарь используем в функции трансформации тестового набора. Предлагаемый класс <code>TfidfVectorizer</code> используем с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_a = TfidfVectorizer()\n",
    "\n",
    "x_train_a = vectorizer_a.fit_transform(x_train)\n",
    "x_test_a = vectorizer_a.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для модифицированного алгоритма, где используется день недели, векторизацию произведем на колонке конкатенированных темы письма и содержания. К результату выполнения векторизации добавим колонку индексов дней недели. В данном случае векторизатор также инициализируем с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_b = TfidfVectorizer()\n",
    "# Добавляем к полученной в результате векторизации разреженной матрице столбец со значениями дней недели\n",
    "x_train_b = sp.sparse.hstack((vectorizer_b.fit_transform(x_train_b.iloc[:, 1]), x_train_b.iloc[:, 0].values.reshape(len(x_train_b.iloc[:, 0]),1)))\n",
    "x_test_b = sp.sparse.hstack((vectorizer_b.transform(x_test_b.iloc[:, 1]), x_test_b.iloc[:, 0].values.reshape(len(x_test_b.iloc[:, 0]),1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В третьем сценарии, где вместо слов используются биграммы для генерации признаков TF-IDF, при инициализации векторизатора укажем параметр <code>ngram_range = (2, 2)</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_c = TfidfVectorizer(ngram_range = (2, 2))\n",
    "\n",
    "x_train_c = vectorizer_c.fit_transform(x_train)\n",
    "x_test_c = vectorizer_c.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация\n",
    "\n",
    "Инициализируем три классификатора с одинаковыми параметрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=10, random_state=65)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=10, n_jobs=10, random_state=65)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, n_jobs=10, random_state=65)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_a = RandomForestClassifier(random_state=65, n_jobs=10, n_estimators=10)\n",
    "rfc_b = RandomForestClassifier(random_state=65, n_jobs=10, n_estimators=10)\n",
    "rfc_c = RandomForestClassifier(random_state=65, n_jobs=10, n_estimators=10)\n",
    "\n",
    "rfc_a.fit(x_train_a, y_train)\n",
    "rfc_b.fit(x_train_b, y_train)\n",
    "rfc_c.fit(x_train_c, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Расчет метрик\n",
    "Для получения метрик удобнее всего воспользоваться модулем `sklearn.metrics`. Выполним предсказания на тестовых данных и выполним оценку полученных моделей для трех случаев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.946     0.990     0.968      4728\n",
      "           1      0.989     0.937     0.962      4239\n",
      "\n",
      "    accuracy                          0.965      8967\n",
      "   macro avg      0.967     0.964     0.965      8967\n",
      "weighted avg      0.966     0.965     0.965      8967\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.949     0.991     0.969      4728\n",
      "           1      0.989     0.941     0.964      4239\n",
      "\n",
      "    accuracy                          0.967      8967\n",
      "   macro avg      0.969     0.966     0.967      8967\n",
      "weighted avg      0.968     0.967     0.967      8967\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.923     0.987     0.954      4728\n",
      "           1      0.984     0.908     0.944      4239\n",
      "\n",
      "    accuracy                          0.949      8967\n",
      "   macro avg      0.953     0.947     0.949      8967\n",
      "weighted avg      0.952     0.949     0.949      8967\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_a = rfc_a.predict(x_test_a)\n",
    "y_pred_b = rfc_b.predict(x_test_b)\n",
    "y_pred_c = rfc_c.predict(x_test_c)\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred_a, digits=3))\n",
    "print(classification_report(y_test, y_pred_b, digits=3))\n",
    "print(classification_report(y_test, y_pred_c, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера сравним первые два сценирия с точки зрения FPR и precision.\n",
    "Для получения FPR достаточно сгенерировать confusion matrix и рассчитать его на основе значений из матрицы, в то время как precision может быть получен с помощью отдельной функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference in FPR: -0.000423011844331642\n",
      "Difference in precision: 0.0005386334269830151\n"
     ]
    }
   ],
   "source": [
    "tn_a, fp_a, _, _  = confusion_matrix(y_test, y_pred_a).ravel()\n",
    "tn_b, fp_b, _, _ = confusion_matrix(y_test, y_pred_b).ravel()\n",
    "\n",
    "fpr_a = fp_a / (fp_a + tn_a)\n",
    "fpr_b = fp_b / (fp_b + tn_b)\n",
    "\n",
    "pr_a = precision_score(y_test, y_pred_a)\n",
    "pr_b = precision_score(y_test, y_pred_b)\n",
    "\n",
    "print(f'Difference in FPR: {fpr_b - fpr_a}')\n",
    "print(f'Difference in precision: {pr_b - pr_a}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assigned class: [0]\n",
      "probability of assigned class: [[  0. -inf]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nshir\\code\\shit\\shitenv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:922: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(proba)\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(os.getcwd(), 'task_4_processed_test_2.csv')) as file:\n",
    "    string = [file.read()]\n",
    "    data = pd.DataFrame(string)\n",
    "vect_data = vectorizer_c.transform(data[0])\n",
    "print('assigned class:',rfc_c.predict(vect_data))\n",
    "print('probability of assigned class:', rfc_c.predict_log_proba(vect_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('shitenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "9da171d52472031140bc913e3da61de2d22566d9b82a055c1dbec25136f8e8ce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
